{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in adult.data from UCL Database\n",
    "adult_data_raw = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None)\n",
    "\n",
    "\n",
    "# Renaming Columns and stripping strings of whitespace\n",
    "cols = ['Age','Workclass','fnlwgt','Education','Education_num','Marital Status','Occupation','Relationship','Race',\n",
    "       'Sex','Capital Gain','Capital Loss','Hours per Week','Country','Salary']\n",
    "adult_data_raw.columns = cols\n",
    "adult_data_raw = adult_data_raw.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "\n",
    "# Dropping all data entries with unknown values and entries where GDP information is unavailable\n",
    "na_indices = []\n",
    "unknown_countries = []\n",
    "for i in range(adult_data_raw.shape[0]):\n",
    "    if '?' in adult_data_raw.iloc[i].values:\n",
    "        na_indices.append(i)\n",
    "    if 'South' in adult_data_raw.iloc[i].values:\n",
    "        unknown_countries.append(i)\n",
    "    if 'Outlying-US(Guam-USVI-etc)' in adult_data_raw.iloc[i].values:\n",
    "        unknown_countries.append(i)\n",
    "    if 'Laos' in adult_data_raw.iloc[i].values:\n",
    "        unknown_countries.append(i)\n",
    "    if 'Taiwan' in adult_data_raw.iloc[i].values:\n",
    "        unknown_countries.append(i)\n",
    "\n",
    "dropped_indices = na_indices + unknown_countries\n",
    "adult_data_raw = adult_data_raw.drop(dropped_indices).reset_index(drop=True)\n",
    "\n",
    "# Ensuring all values in Age are numeric\n",
    "adult_data_raw['Age'] = pd.to_numeric(adult_data_raw['Age'])\n",
    "\n",
    "# Consolidating and encoding Workclass to:\n",
    "# Not-working: 0, Private: 1, Self-emp: 2, Government: 3\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].astype(str)\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Never-worked', 'Not-working')\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Without-pay', 'Not-working')\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Self-emp-not-inc', 'Self-emp')\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Self-emp-inc', 'Self-emp')\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Local-gov', 'Government')\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('State-gov', 'Government')\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Federal-gov', 'Government')\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Not-working', 0)\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Private', 1)\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Self-emp', 2)\n",
    "adult_data_raw['Workclass'] = adult_data_raw['Workclass'].replace('Government', 3)\n",
    "adult_data_raw['Workclass'] = pd.to_numeric(adult_data_raw['Workclass'])\n",
    "\n",
    "# Dropping fnlwgt column beacuse it does not appear to provide value to classification\n",
    "adult_data_raw = adult_data_raw.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Consolidating and encoding Education to:\n",
    "# Dropout: 0, HS-grad: 1, Prof-school: 2, Associates: 3, Bachelors: 4, Masters: 5, Doctorate: 6\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].astype(str)\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Some-college', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Assoc-voc', 'Associates')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('11th', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Assoc-acdm', 'Associates')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('10th', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('7th-8th', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('9th', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('12th', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('5th-6th', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('1st-4th', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Preschool', 'Dropout')\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Dropout', 0)\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('HS-grad', 1)\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Prof-school', 2)\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Associates', 3)\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Bachelors', 4)\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Masters', 5)\n",
    "adult_data_raw['Education'] = adult_data_raw['Education'].replace('Doctorate', 6)\n",
    "adult_data_raw['Education'] = pd.to_numeric(adult_data_raw['Education'])\n",
    "\n",
    "# Dropping Education_num in favor of using encoded Education column\n",
    "adult_data_raw = adult_data_raw.drop('Education_num', axis=1)\n",
    "\n",
    "\n",
    "# Consolidating and encoding Marital Status to:\n",
    "# Married: 0 , Single: 1, Divorced: 2, Separated: 3, Widowed: 4\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].astype(str)\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Married-civ-spouse', 'Married')\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Never-married', 'Single')\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Married-spouse-absent', 'Married')\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Married-AF-spouse', 'Married')\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Married', 0)\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Single', 1)\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Divorced', 2)\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Separated', 3)\n",
    "adult_data_raw['Marital Status'] = adult_data_raw['Marital Status'].replace('Widowed', 4)\n",
    "adult_data_raw['Marital Status'] = pd.to_numeric(adult_data_raw['Marital Status'])\n",
    "\n",
    "\n",
    "# Consolidating and encoding Occupation to:\n",
    "# White-collar:0 , Blue-collar: 1, Pink-collar:2 , Other-service: 3\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].astype(str)\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Prof-specialty', 'White-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Craft-repair', 'Blue-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Exec-managerial', 'White-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Adm-clerical', 'White-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Sales', 'Pink-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Machine-op-inspct', 'Blue-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Transport-moving', 'Blue-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Handlers-cleaners', 'Blue-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Tech-support', 'Pink-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Farming-fishing', 'Blue-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Protective-serv', 'Pink-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Priv-house-serv', 'Blue-collar')\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('White-collar', 0)\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Blue-collar', 1)\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Pink-collar', 2)\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Other-service', 3)\n",
    "adult_data_raw['Occupation'] = adult_data_raw['Occupation'].replace('Armed-Forces', 5)\n",
    "adult_data_raw['Occupation'] = pd.to_numeric(adult_data_raw['Occupation'])\n",
    "\n",
    "# Consolidating and encoding Relationship to:\n",
    "# Not-in-family: 0, Unmarried: 1, Other-relative: 2, Own-child: 3, Wife: 4, Husband: 5\n",
    "adult_data_raw['Relationship'] = adult_data_raw['Relationship'].astype(str)\n",
    "adult_data_raw['Relationship'] = adult_data_raw['Relationship'].replace('Not-in-family', 0)\n",
    "adult_data_raw['Relationship'] = adult_data_raw['Relationship'].replace('Unmarried', 1)\n",
    "adult_data_raw['Relationship'] = adult_data_raw['Relationship'].replace('Other-relative', 2)\n",
    "adult_data_raw['Relationship'] = adult_data_raw['Relationship'].replace('Own-child', 3)\n",
    "adult_data_raw['Relationship'] = adult_data_raw['Relationship'].replace('Wife', 4)\n",
    "adult_data_raw['Relationship'] = adult_data_raw['Relationship'].replace('Husband', 5)\n",
    "adult_data_raw['Relationship'] = pd.to_numeric(adult_data_raw['Relationship'])\n",
    "\n",
    "# Consolidating and encoding Race to:\n",
    "# Other: 0, Amer-Indian-Eskimo: 1, Asian-Pac-Islander: 2, Black: 3, White: 4\n",
    "adult_data_raw['Race'] = adult_data_raw['Race'].astype(str)\n",
    "adult_data_raw['Race'] = adult_data_raw['Race'].replace('Other', 0)\n",
    "adult_data_raw['Race'] = adult_data_raw['Race'].replace('Amer-Indian-Eskimo', 1)\n",
    "adult_data_raw['Race'] = adult_data_raw['Race'].replace('Asian-Pac-Islander', 2)\n",
    "adult_data_raw['Race'] = adult_data_raw['Race'].replace('Black', 3)\n",
    "adult_data_raw['Race'] = adult_data_raw['Race'].replace('White', 4)\n",
    "adult_data_raw['Race'] = pd.to_numeric(adult_data_raw['Race'])\n",
    "\n",
    "# Converting Sex to 1 if Male and 0 if Female\n",
    "adult_data_raw['Sex'] = adult_data_raw['Sex'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "\n",
    "# Ensuring all Capital Gain, Capital Loss, and Hours per week values are numeric\n",
    "adult_data_raw['Capital Gain'] = pd.to_numeric(adult_data_raw['Capital Gain'])\n",
    "adult_data_raw['Capital Loss'] = pd.to_numeric(adult_data_raw['Capital Loss'])\n",
    "adult_data_raw['Hours per Week'] = pd.to_numeric(adult_data_raw['Hours per Week'])\n",
    "\n",
    "# Consolidating certain countries to conincide with information on GDP per Country \n",
    "adult_data_raw['Country'] = adult_data_raw['Country'].astype(str)\n",
    "adult_data_raw['Country'] = adult_data_raw['Country'].replace('Scotland', 'United Kingdom')\n",
    "adult_data_raw['Country'] = adult_data_raw['Country'].replace('England', 'United Kingdom')\n",
    "adult_data_raw['Country'] = adult_data_raw['Country'].replace('Trinadad&Tobago', 'Trinidad and Tobago')\n",
    "adult_data_raw['Country'] = adult_data_raw['Country'].replace('Hong', 'Hong Kong SAR, China')\n",
    "adult_data_raw['Country'] = adult_data_raw['Country'].replace('Holand-Netherlands', 'Netherlands')\n",
    "adult_data_raw['Country'] = adult_data_raw['Country'].replace('Columbia', 'Colombia')\n",
    "\n",
    "# Converting Salary to 1 if >50k and 0 if <= to 50k\n",
    "adult_data_raw['Salary'] = adult_data_raw['Salary'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "# Rearranging columns for readability\n",
    "new_cols = ['Age','Workclass','Education','Marital Status','Occupation','Relationship','Race',\n",
    "            'Sex','Capital Gain','Capital Loss','Hours per Week','Country','Salary']\n",
    "adult_data_raw = adult_data_raw[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per Week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Workclass  Education  Marital Status  Occupation  Relationship  Race  \\\n",
       "0   39          3          4               1           0             0     4   \n",
       "1   50          2          4               0           0             5     4   \n",
       "2   38          1          1               2           1             0     4   \n",
       "3   53          1          0               0           1             5     3   \n",
       "4   28          1          4               0           0             4     3   \n",
       "\n",
       "   Sex  Capital Gain  Capital Loss  Hours per Week        Country  Salary  \n",
       "0    1          2174             0              40  United-States       0  \n",
       "1    1             0             0              13  United-States       0  \n",
       "2    1             0             0              40  United-States       0  \n",
       "3    1             0             0              40  United-States       0  \n",
       "4    0             0             0              40           Cuba       0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Workclass  Education  Marital Status  Occupation  Relationship  Race  \\\n",
       "0   39          3          4               1           0             0     4   \n",
       "1   50          2          4               0           0             5     4   \n",
       "2   38          1          1               2           1             0     4   \n",
       "3   53          1          0               0           1             5     3   \n",
       "4   28          1          4               0           0             4     3   \n",
       "\n",
       "   Sex  Capital Gain  Capital Loss  Hours per Week  \n",
       "0    1          2174             0              40  \n",
       "1    1             0             0              13  \n",
       "2    1             0             0              40  \n",
       "3    1             0             0              40  \n",
       "4    0             0             0              40  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['Age', 'Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', \n",
    "            'Capital Gain', 'Capital Loss', 'Hours per Week', 'Salary']\n",
    "data = adult_data_raw[features]\n",
    "\n",
    "# # Likelihood encoding for categorical variables\n",
    "# categorical_variables = ['Workclass','Education','Marital Status','Occupation','Relationship','Race']\n",
    "# large_salary = data.loc[data['Salary'] == 1] \n",
    "# for category in categorical_variables:\n",
    "#     unique_vals = list(data[category].unique())\n",
    "#     x_value_counts = dict(large_salary[category].value_counts())\n",
    "#     missing_vals = list(set(unique_vals).difference(list(x_value_counts.keys())))\n",
    "#     for missing in missing_vals:\n",
    "#         x_value_counts.update({missing: 0})\n",
    "#     y_value_counts = dict(data[category].value_counts())\n",
    "#     likelihood = {k: x_value_counts[k] / y_value_counts[k] for k in y_value_counts if k in x_value_counts}\n",
    "#     data[category].replace(likelihood, inplace=True)\n",
    "    \n",
    "X = data.drop(['Salary'], axis=1)\n",
    "Y = data['Salary']\n",
    "# X = X.apply(stats.zscore)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='logistic', hidden_layer_sizes=(100,))\n",
    "mlp.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233060163901659"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 3,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8779399027250316"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Using the Adult data set from UCI database; classifying whether or not an adult makes more or less than 50K a year based on feature values.\n",
    "\n",
    "Features being used: Age, Workclass, Education, Martial Status, Occupation, Relationship, Sex, Capital Gain, Captial Loss, and Hours per week\n",
    "\n",
    "Note: Impact (Likelihood) Encoding and zscore normalization introdcued to observe performance changes\n",
    "\n",
    "Algorithims Run: Neural Network and Boosted Tree Classifer\n",
    "\n",
    "Results:\n",
    "    - Cleaned Data \n",
    "        - Neural Network; Logistic; (100,)                  ->   0.8233\n",
    "        - Neural Network; Logistic; (50, 75, 25,)           ->   0.8262\n",
    "        \n",
    "        - Neural Network; Hyperbolic Tangent; (100,)        ->   0.8240\n",
    "        - Neural Network; Hyperbolic Tangent; (50, 75, 25,) ->   0.8054\n",
    "\n",
    "        - Boosted Tree Classifer; Deviance; Depth=3         ->   0.8779\n",
    "    - Z-Score \n",
    "        - Neural Network; Logistic; (100,)                  ->   0.8415\n",
    "        - Neural Network; Logistic; (50, 75, 25,)           ->   0.8422\n",
    "        \n",
    "        - Neural Network; Hyperbolic Tangent; (100,)        ->   0.8489\n",
    "        - Neural Network; Hyperbolic Tangent; (50, 75, 25,) ->   0.8798\n",
    "\n",
    "        - Boosted Tree Classifer; Deviance; Depth=3         ->   0.8779\n",
    "    - Impact Encoding \n",
    "        - Neural Network; Logistic; (100,)                  ->   0.8293\n",
    "        - Neural Network; Logistic; (50, 75, 25,)           ->   0.8301\n",
    "        \n",
    "        - Neural Network; Hyperbolic Tangent; (100,)        ->   0.8254\n",
    "        - Neural Network; Hyperbolic Tangent; (50, 75, 25,) ->   0.8268\n",
    "\n",
    "        - Boosted Tree Classifer; Deviance; Depth=3         ->   0.8796\n",
    "    - Impact Encoding and Z-Score\n",
    "        - Neural Network; Logistic; (100,)                  ->   0.8463\n",
    "        - Neural Network; Logistic; (50, 75, 25,)           ->   0.8472\n",
    "        \n",
    "        - Neural Network; Hyperbolic Tangent; (100,)        ->   0.8503\n",
    "        - Neural Network; Hyperbolic Tangent; (50, 75, 25,) ->   0.8645\n",
    "\n",
    "        - Boosted Tree Classifer; Deviance; Depth=3         ->   0.8779\n",
    "\n",
    "#### Notes:\n",
    "The boosted tree classifier with depth of 3 and deviance loss function consistently produced results of accuracy greater than 87% proving a better model for this data.  However, it took slightly longer to run the algorithim.\n",
    "\n",
    "The neural networks also provided results of accuracy above 80% in all cases showing it to be a strong algorithim as well.  There were various cases where different shapes of the neural network and activation function proved either the hyperbolic tangent or sigmoid function to outperform the other by a slight margin.\n",
    "\n",
    "For the best practice for adjusting the data, z-score normalization and the combination of both impact encoding and z-score normalization produced the highest results across all models and variations.\n",
    "\n",
    "The variations in complexity was as follows: in most cases, the boosted tree classifier took slightly more time over the neural networks.  Using the hyperbolic tangent activation function over the sigmoid function took more time in some cases but not all.  The sigmoid activation function was, if not the fastest, close to it in all cases.  Final note, the additional hidden layers took more time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
